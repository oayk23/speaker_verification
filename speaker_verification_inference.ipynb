{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b716d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omera\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ä°ÅŸlem yapÄ±lan cihaz: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ecapa_model import ECAPA_TDNN  # Dosya yanÄ±ndaysa bunu kullan\n",
    "\n",
    "# EÄŸer import hatasÄ± alÄ±rsan yukarÄ±daki satÄ±rÄ± silip ECAPA_TDNN class'Ä±nÄ± buraya yapÄ±ÅŸtÄ±rabilirsin.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Ä°ÅŸlem yapÄ±lan cihaz: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a625eb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model yÃ¼kleniyor: C:\\Users\\omera\\Desktop\\youtube_data\\models\\model_0023.model\n",
      "Model baÅŸarÄ±yla yÃ¼klendi ve hazÄ±r!\n"
     ]
    }
   ],
   "source": [
    "def load_trained_model(model_path, C=256, emb_size=128):\n",
    "    # Modeli baÅŸlat (Backbone)\n",
    "    model = ECAPA_TDNN(C=C).to(device)\n",
    "    \n",
    "    print(f\"Model yÃ¼kleniyor: {model_path}\")\n",
    "    \n",
    "    # Checkpoint'i yÃ¼kle\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # State Dict temizliÄŸi (speaker_encoder. prefixini atÄ±yoruz)\n",
    "    model_state = model.state_dict()\n",
    "    new_state = {}\n",
    "    \n",
    "    for k, v in checkpoint.items():\n",
    "        # Sadece encoder parametrelerini al\n",
    "        if k.startswith(\"speaker_encoder.\"):\n",
    "            name = k.replace(\"speaker_encoder.\", \"\")\n",
    "            new_state[name] = v\n",
    "            \n",
    "    # Parametreleri yÃ¼kle\n",
    "    model.load_state_dict(new_state)\n",
    "    model.eval() # Inference moduna al\n",
    "    print(\"Model baÅŸarÄ±yla yÃ¼klendi ve hazÄ±r!\")\n",
    "    return model\n",
    "\n",
    "# 22. Epoch modelini buraya tanÄ±mla\n",
    "MODEL_PATH = r\"C:\\Users\\omera\\Desktop\\youtube_data\\models\\model_0023.model\" # Veya senin kaydettiÄŸin tam yol\n",
    "model = load_trained_model(MODEL_PATH, C=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2932393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, audio_path):\n",
    "    if not os.path.exists(audio_path):\n",
    "        raise FileNotFoundError(f\"Dosya bulunamadÄ±: {audio_path}\")\n",
    "        \n",
    "    # 1. Sesi YÃ¼kle\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # 2. Resample (EÄŸer 24k deÄŸilse)\n",
    "    if sr != 24000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=24000)\n",
    "        wav = resampler(wav)\n",
    "        \n",
    "    # 3. Stereo ise Mono yap\n",
    "    if wav.shape[0] > 1:\n",
    "        wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "        \n",
    "    # 4. Modele Ver (Batch boyutu ekle: [1, samples])\n",
    "    wav = wav.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # aug=False Ã¶nemli! Testte gÃ¼rÃ¼ltÃ¼ eklemiyoruz.\n",
    "        embedding = model(wav, aug=False)\n",
    "        \n",
    "    return embedding\n",
    "\n",
    "def compare_files(file1, file2):\n",
    "    emb1 = get_embedding(model, file1)\n",
    "    emb2 = get_embedding(model, file2)\n",
    "    \n",
    "    # Cosine Similarity\n",
    "    similarity = nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "    score = similarity(emb1, emb2).item()\n",
    "    \n",
    "    return score\n",
    "\n",
    "def interpret_score(score):\n",
    "    print(f\"Benzerlik Skoru: {score:.4f}\")\n",
    "    if score > 0.45:\n",
    "        print(\"âœ… SONUÃ‡: KESÄ°NLÄ°KLE AYNI KÄ°ÅžÄ°\")\n",
    "    elif score > 0.35:\n",
    "        print(\"ðŸ¤” SONUÃ‡: MUHTEMELEN AYNI KÄ°ÅžÄ° (SÄ±nÄ±rda)\")\n",
    "    else:\n",
    "        print(\"âŒ SONUÃ‡: FARKLI KÄ°ÅžÄ°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705158cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST 1: Kendi Sesin vs Kendi Sesin ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omera\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benzerlik Skoru: 0.8934\n",
      "âœ… SONUÃ‡: KESÄ°NLÄ°KLE AYNI KÄ°ÅžÄ°\n",
      "\n",
      "--- TEST 2: Kendi Sesin vs BaÅŸkasÄ± ---\n",
      "Benzerlik Skoru: 0.2042\n",
      "âŒ SONUÃ‡: FARKLI KÄ°ÅžÄ°\n"
     ]
    }
   ],
   "source": [
    "my_voice_1 = r\"C:\\Users\\omera\\Desktop\\youtube_data\\speaker_verification\\omer_deneme.wav\"      # Senin yÃ¼klediÄŸin 1. kayÄ±t\n",
    "my_voice_2 = r\"C:\\Users\\omera\\Desktop\\youtube_data\\speaker_verification\\omer_deneme_2.wav\"    # Senin yÃ¼klediÄŸin 2. kayÄ±t\n",
    "\n",
    "# Datasetten rastgele bir baÅŸkasÄ± (CSV'den veya klasÃ¶rden bakÄ±p yolunu yaz)\n",
    "# Ã–rnek: \"dataset/baska_bir_konusmaci/ses_dosyasi.wav\"\n",
    "other_voice = r\"C:\\Users\\omera\\Desktop\\youtube_data\\speaker_verification\\baskasi.wav\" # BurayÄ± kendi datasetine gÃ¶re dÃ¼zenle!\n",
    "\n",
    "print(\"--- TEST 1: Kendi Sesin vs Kendi Sesin ---\")\n",
    "if os.path.exists(my_voice_1) and os.path.exists(my_voice_2):\n",
    "    score = compare_files(my_voice_1, my_voice_2)\n",
    "    interpret_score(score)\n",
    "else:\n",
    "    print(\"LÃ¼tfen ses dosyalarÄ±nÄ± yÃ¼klediÄŸinden emin ol!\")\n",
    "\n",
    "print(\"\\n--- TEST 2: Kendi Sesin vs BaÅŸkasÄ± ---\")\n",
    "if os.path.exists(my_voice_1) and os.path.exists(other_voice):\n",
    "    score = compare_files(my_voice_1, other_voice)\n",
    "    interpret_score(score)\n",
    "else:\n",
    "    print(\"Dataset dosya yolunu kontrol et!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58fc0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import time\n",
    "import soundfile as sf\n",
    "SAMPLE_RATE = 24000  # Modelin eÄŸitimiyle aynÄ± olmalÄ±!\n",
    "DURATION = 4         # KaÃ§ saniye kayÄ±t alacaÄŸÄ±\n",
    "CHANNELS = 1         # Mono kayÄ±t\n",
    "\n",
    "def record_audio(filename, duration=DURATION, fs=SAMPLE_RATE):\n",
    "    print(f\"\\nðŸŽ¤ KAYIT BAÅžLIYOR ({duration} saniye)...\")\n",
    "    print(f\"LÃ¼tfen konuÅŸun: '{filename}' iÃ§in kayÄ±t alÄ±nÄ±yor.\")\n",
    "    time.sleep(0.5) # HazÄ±rlÄ±k iÃ§in kÄ±sa bekleme\n",
    "    \n",
    "    # KayÄ±t iÅŸlemi\n",
    "    my_recording = sd.rec(int(duration * fs), samplerate=fs, channels=CHANNELS)\n",
    "    sd.wait()  # KaydÄ±n bitmesini bekle\n",
    "    \n",
    "    print(\"âœ… KayÄ±t tamamlandÄ±.\")\n",
    "    # DosyayÄ± kaydet\n",
    "    sf.write(filename, my_recording, fs)\n",
    "    print(f\"Dosya kaydedildi: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3837c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¤ KAYIT BAÅžLIYOR (4 saniye)...\n",
      "LÃ¼tfen konuÅŸun: 'omer_deneme.wav' iÃ§in kayÄ±t alÄ±nÄ±yor.\n",
      "âœ… KayÄ±t tamamlandÄ±.\n",
      "Dosya kaydedildi: omer_deneme.wav\n"
     ]
    }
   ],
   "source": [
    "record_audio(\"omer_deneme.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49197ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¤ KAYIT BAÅžLIYOR (4 saniye)...\n",
      "LÃ¼tfen konuÅŸun: 'omer_deneme_2.wav' iÃ§in kayÄ±t alÄ±nÄ±yor.\n",
      "âœ… KayÄ±t tamamlandÄ±.\n",
      "Dosya kaydedildi: omer_deneme_2.wav\n"
     ]
    }
   ],
   "source": [
    "record_audio(\"omer_deneme_2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b8e24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Okunuyor: C:\\Users\\omera\\Desktop\\speaker_verification\\artifacts\\val_split.csv\n",
      "Uygun KonuÅŸmacÄ± SayÄ±sÄ±: 2143\n",
      "Pozitif Ã§iftler Ã¼retiliyor...\n",
      "Negatif Ã§iftler Ã¼retiliyor...\n",
      "âœ… BaÅŸarÄ±lÄ±! 10000 Ã§ift 'test_pairs_static.csv' dosyasÄ±na kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "# --- AYARLAR ---\n",
    "VAL_CSV_PATH = r\"C:\\Users\\omera\\Desktop\\speaker_verification\\artifacts\\val_split.csv\"  # Senin ayÄ±rdÄ±ÄŸÄ±n validasyon dosyasÄ±\n",
    "ROOT_PATH = r\"C:\\Users\\omera\\Desktop\\youtube_data\\dataset\"                   # DosyalarÄ±n olduÄŸu ana klasÃ¶r\n",
    "OUTPUT_FILE = \"test_pairs_static.csv\"   # Ã‡Ä±ktÄ± dosyasÄ±\n",
    "NUM_PAIRS = 10000                       # Toplam Ã§ift sayÄ±sÄ± (5000 Pozitif + 5000 Negatif)\n",
    "SEED = 42                               # Sabit sonuÃ§ iÃ§in random seed\n",
    "\n",
    "def generate_static_pairs():\n",
    "    random.seed(SEED)\n",
    "    print(f\"CSV Okunuyor: {VAL_CSV_PATH}\")\n",
    "    \n",
    "    # CSV'yi oku\n",
    "    df = pd.read_csv(VAL_CSV_PATH,sep=\"|\")\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    \n",
    "    # Kolon isimlerini belirle\n",
    "    spk_col = 'speaker' if 'speaker' in df.columns else df.columns[2]\n",
    "    aud_col = 'audio_path' if 'audio_path' in df.columns else df.columns[0]\n",
    "    \n",
    "    # Speaker -> Dosya Listesi haritasÄ± Ã§Ä±kar\n",
    "    spk_to_files = {}\n",
    "    for _, row in df.iterrows():\n",
    "        spk = row[spk_col]\n",
    "        fname = row[aud_col]\n",
    "        full_path = os.path.join(ROOT_PATH, str(spk), str(fname))\n",
    "        \n",
    "        # Dosya var mÄ± kontrol et (Gereksiz hata almamak iÃ§in)\n",
    "        if os.path.exists(full_path):\n",
    "            if spk not in spk_to_files:\n",
    "                spk_to_files[spk] = []\n",
    "            spk_to_files[spk].append(full_path)\n",
    "\n",
    "    # En az 2 dosyasÄ± olanlar (Pozitif Ã§ift iÃ§in)\n",
    "    valid_speakers = [s for s in spk_to_files if len(spk_to_files[s]) >= 2]\n",
    "    all_speakers = list(spk_to_files.keys())\n",
    "    \n",
    "    print(f\"Uygun KonuÅŸmacÄ± SayÄ±sÄ±: {len(valid_speakers)}\")\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    # 1. Pozitif Ã‡iftler (AynÄ± KiÅŸi)\n",
    "    print(\"Pozitif Ã§iftler Ã¼retiliyor...\")\n",
    "    target_pos = NUM_PAIRS // 2\n",
    "    for _ in range(target_pos):\n",
    "        spk = random.choice(valid_speakers)\n",
    "        f1, f2 = random.sample(spk_to_files[spk], 2)\n",
    "        pairs.append([f1, f2, 1]) # 1 = AynÄ±\n",
    "\n",
    "    # 2. Negatif Ã‡iftler (FarklÄ± KiÅŸi)\n",
    "    print(\"Negatif Ã§iftler Ã¼retiliyor...\")\n",
    "    target_neg = NUM_PAIRS // 2\n",
    "    for _ in range(target_neg):\n",
    "        spk1, spk2 = random.sample(all_speakers, 2)\n",
    "        while spk1 == spk2: # FarklÄ± olmasÄ±nÄ± garanti et\n",
    "            spk2 = random.choice(all_speakers)\n",
    "            \n",
    "        f1 = random.choice(spk_to_files[spk1])\n",
    "        f2 = random.choice(spk_to_files[spk2])\n",
    "        pairs.append([f1, f2, 0]) # 0 = FarklÄ±\n",
    "        \n",
    "    # KarÄ±ÅŸtÄ±r ve Kaydet\n",
    "    random.shuffle(pairs)\n",
    "    \n",
    "    # DataFrame olarak kaydet\n",
    "    out_df = pd.DataFrame(pairs, columns=['file1', 'file2', 'label'])\n",
    "    out_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"âœ… BaÅŸarÄ±lÄ±! {len(pairs)} Ã§ift '{OUTPUT_FILE}' dosyasÄ±na kaydedildi.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_static_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03ee76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
