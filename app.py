import gradio as gr
import torch
import torchaudio
import os
import numpy as np
from ecapa_model import ECAPA_TDNN 

# --- AYARLAR ---
MODEL_PATH = "artifacts\model_0057.model" # Model yolunu kontrol et!
THRESHOLD = 0.30  # Senin testlerinde bulduÄŸun optimal eÅŸik (0.2993)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- MODELÄ° YÃœKLE ---
def load_model():
    print("Model yÃ¼kleniyor...")
    model = ECAPA_TDNN(C=256).to(DEVICE)
    
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
        new_state = {}
        for k, v in checkpoint.items():
            if k.startswith("speaker_encoder."):
                new_state[k.replace("speaker_encoder.", "")] = v
        model.load_state_dict(new_state)
        model.eval()
        print("âœ… Model hazÄ±r!")
        return model
    else:
        print(f"âŒ HATA: Model dosyasÄ± bulunamadÄ±: {MODEL_PATH}")
        return None

model = load_model()

# --- GELÄ°ÅMÄ°Å SES Ä°ÅLEME FONKSÄ°YONU ---
def preprocess_audio(wav_path):
    """
    Sesi yÃ¼kler, resample yapar, mono'ya Ã§evirir, sessizliÄŸi atar ve normalize eder.
    """
    try:
        # 1. YÃ¼kle
        wav, sr = torchaudio.load(wav_path)
        
        # 2. Resample (24kHz)
        if sr != 24000:
            resampler = torchaudio.transforms.Resample(sr, 24000)
            wav = resampler(wav)
            
        # 3. Mono Yap
        if wav.shape[0] > 1: 
            wav = torch.mean(wav, dim=0, keepdim=True)

        # 4. Basit Sessizlik Temizleme (Trim Silence)
        # Enerjisi Ã§ok dÃ¼ÅŸÃ¼k olan baÅŸtaki ve sondaki kÄ±sÄ±mlarÄ± at
        # (Basit bir yÃ¶ntem: Mutlak deÄŸer ortalamasÄ±nÄ±n %10'u altÄ±nÄ± sessizlik say)
        threshold = wav.abs().mean() * 0.1
        mask = wav.abs() > threshold
        # Mask'in True olduÄŸu ilk ve son indexi bul
        indices = torch.nonzero(mask)
        
        if indices.numel() > 0:
            start = indices.min()
            end = indices.max()
            wav = wav[:, start:end+1]
        
        # EÄŸer Ã§ok kÄ±sa kaldÄ±ysa (Ã¶rn: sadece gÃ¼rÃ¼ltÃ¼ varsa) orijinali kullan
        if wav.shape[1] < 2400: # 0.1 saniyeden kÄ±saysa
            wav, _ = torchaudio.load(wav_path) # BaÅŸa dÃ¶n
            if wav.shape[0] > 1: wav = torch.mean(wav, dim=0, keepdim=True)
            if sr != 24000: wav = torchaudio.transforms.Resample(sr, 24000)(wav)

        # 5. Peak Normalization (En Ã¶nemlisi bu!)
        # Sesi -1 ile +1 arasÄ±na yayar
        max_val = torch.abs(wav).max()
        if max_val > 0:
            wav = wav / max_val
            
        return wav.to(DEVICE)
        
    except Exception as e:
        print(f"Preprocess HatasÄ±: {e}")
        return None

def get_embedding(wav_tensor):
    with torch.no_grad():
        # Batch boyutu ekle [1, samples]
        if wav_tensor.dim() == 2:
            wav_tensor = wav_tensor
        else:
            wav_tensor = wav_tensor.unsqueeze(0)
            
        emb = model(wav_tensor, aug=False)
    return emb

def compare_speakers(audio1, audio2):
    if model is None:
        return 0, "Model YÃ¼klenemedi!", "error"
    
    if not audio1 or not audio2:
        return 0, "LÃ¼tfen iki ses dosyasÄ±nÄ± da yÃ¼kleyin/kaydedin."
    
    # Ä°ÅŸle
    wav1 = preprocess_audio(audio1)
    wav2 = preprocess_audio(audio2)
    
    if wav1 is None or wav2 is None:
        return 0, "Ses iÅŸlenirken hata oluÅŸtu."

    # Embedding Al
    emb1 = get_embedding(wav1)
    emb2 = get_embedding(wav2)
    
    # Skorla
    score = torch.nn.CosineSimilarity(dim=-1)(emb1, emb2).item()
    
    # SonuÃ§ Metni
    score_display = float(f"{score:.4f}")
    
    if score > THRESHOLD:
        result_text = f"âœ… AYNI KÄ°ÅÄ° (EÅŸleÅŸti)"
        # GÃ¼ven seviyesi ekleyelim
        confidence = min((score - THRESHOLD) / (1 - THRESHOLD) * 100 + 50, 99)
        result_text += f"\nGÃ¼ven: %{confidence:.1f}"
    elif score > (THRESHOLD - 0.10):
        result_text = f"ğŸ¤” BELÄ°RSÄ°Z (Gri Alan)"
    else:
        result_text = f"âŒ FARKLI KÄ°ÅÄ°"
        
    return score_display, result_text

# --- ARAYÃœZ ---
css = """
#result_box {
    font-size: 22px; 
    font-weight: bold; 
    text-align: center;
    padding: 20px;
}
"""

with gr.Blocks(title="Mini-ECAPA Demo", theme=gr.themes.Soft(), css=css) as demo:
    gr.Markdown(
        """
        # ğŸ¤ Mini-ECAPA: TÃ¼rkÃ§e Ses DoÄŸrulama
        **Model:** Custom Mini-ECAPA (16MB) | **EÄŸitim:** 500 Saat TÃ¼rkÃ§e Veri | **Performans:** %0.56 EER
        """
    )
    
    with gr.Row():
        with gr.Column():
            audio_input1 = gr.Audio(sources=["microphone", "upload"], type="filepath", label="Ses 1 (Referans)")
        with gr.Column():
            audio_input2 = gr.Audio(sources=["microphone", "upload"], type="filepath", label="Ses 2 (Test)")
            
    submit_btn = gr.Button("ğŸ” KarÅŸÄ±laÅŸtÄ±r", variant="primary", size="lg")
    
    with gr.Row():
        score_output = gr.Number(label="Benzerlik Skoru", precision=4)
        text_output = gr.Textbox(label="SonuÃ§", elem_id="result_box")
    
    submit_btn.click(
        fn=compare_speakers,
        inputs=[audio_input1, audio_input2],
        outputs=[score_output, text_output]
    )
    
    gr.Markdown("--- \n *GeliÅŸtirilmiÅŸ Preprocessing (Normalization + Trim) Aktif*")

if __name__ == "__main__":
    demo.launch(share=True)