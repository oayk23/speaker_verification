{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36afa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HÃœCRE 1: KÃ¼tÃ¼phaneler ve Ayarlar\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Senin model dosyan\n",
    "from ecapa_model import ECAPA_TDNN \n",
    "\n",
    "# Orijinal Model iÃ§in SpeechBrain\n",
    "from speechbrain.inference.speaker import EncoderClassifier\n",
    "\n",
    "# AYARLAR\n",
    "PAIRS_FILE = \"test_pairs_static.csv\"   # Az Ã¶nce Ã¼rettiÄŸimiz dosya\n",
    "MY_MODEL_PATH = \"artifacts\\model_0057.model\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Test CihazÄ±: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0835c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ä°ndiriliyor: https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\n",
      "âœ… Ä°ndirme tamamlandÄ±!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "url = \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\"\n",
    "save_path = \"veri_test.txt\"\n",
    "\n",
    "print(f\"Ä°ndiriliyor: {url}\")\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(save_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"âœ… Ä°ndirme tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062d8f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-ECAPA (C=256) YÃ¼kleniyor...\n",
      "Test listesi okunuyor: C:\\Users\\omera\\Desktop\\speaker_verification\\veri_test.txt\n",
      "Toplam Test Ã‡ifti: 37720\n",
      "Benchmark BaÅŸlÄ±yor... (Bu iÅŸlem biraz sÃ¼rebilir)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37720 [00:00<?, ?it/s]C:\\Users\\omera\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37720/37720 [33:13<00:00, 18.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "VOXCELEB1 TEST SONUÃ‡LARI\n",
      "==================================================\n",
      "Model: Custom Mini-ECAPA (24kHz, Clean-Trained)\n",
      "âœ… EER: %21.95\n",
      "Optimal Threshold: 0.3523\n",
      "--------------------------------------------------\n",
      "YORUM:\n",
      "NORMAL. Modelin sadece temiz TÃ¼rkÃ§e sese Ã¶zelleÅŸmiÅŸ (Domain Gap).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "from tqdm import tqdm\n",
    "from ecapa_model import ECAPA_TDNN\n",
    "\n",
    "# --- AYARLAR ---\n",
    "# VoxCeleb1'in \"wav\" klasÃ¶rÃ¼nÃ¼n olduÄŸu ana yol\n",
    "VOXCELEB_ROOT = r\"C:\\Users\\omera\\Desktop\\speaker_verification\\vox1_test_wav\\wav\"  \n",
    "# Resmi test listesi (veri_test.txt) yolu\n",
    "TEST_LIST_PATH = r\"C:\\Users\\omera\\Desktop\\speaker_verification\\veri_test.txt\" \n",
    "# Senin Modelin\n",
    "MODEL_PATH = r\"C:\\Users\\omera\\Desktop\\speaker_verification\\artifacts\\model_0057.model\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_custom_model():\n",
    "    print(f\"Mini-ECAPA (C=256) YÃ¼kleniyor...\")\n",
    "    model = ECAPA_TDNN(C=256).to(device)\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    \n",
    "    # Prefix temizliÄŸi\n",
    "    new_state = {}\n",
    "    for k, v in checkpoint.items():\n",
    "        if k.startswith(\"speaker_encoder.\"):\n",
    "            new_state[k.replace(\"speaker_encoder.\", \"\")] = v\n",
    "    \n",
    "    model.load_state_dict(new_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_embedding(model, file_path):\n",
    "    # Dosya yolu dÃ¼zeltme (Windows/Linux slash farkÄ± iÃ§in)\n",
    "    full_path = os.path.join(VOXCELEB_ROOT, file_path)\n",
    "    \n",
    "    try:\n",
    "        wav, sr = torchaudio.load(full_path)\n",
    "        \n",
    "        # --- KRÄ°TÄ°K NOKTA: RESAMPLE ---\n",
    "        # VoxCeleb 16kHz'dir. Senin modelin 24kHz.\n",
    "        if sr != 24000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 24000)\n",
    "            wav = resampler(wav)\n",
    "            \n",
    "        # Mono yap\n",
    "        if wav.shape[0] > 1: \n",
    "            wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "            \n",
    "        wav = wav.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            emb = model(wav, aug=False)\n",
    "        return emb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Hata ({file_path}): {e}\")\n",
    "        return None\n",
    "\n",
    "def run_voxceleb_benchmark():\n",
    "    model = load_custom_model()\n",
    "    \n",
    "    # Listeyi oku\n",
    "    print(f\"Test listesi okunuyor: {TEST_LIST_PATH}\")\n",
    "    with open(TEST_LIST_PATH, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    scores = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Toplam Test Ã‡ifti: {len(lines)}\")\n",
    "    print(\"Benchmark BaÅŸlÄ±yor... (Bu iÅŸlem biraz sÃ¼rebilir)\")\n",
    "    \n",
    "    # TQDM ile ilerleme Ã§ubuÄŸu\n",
    "    for line in tqdm(lines):\n",
    "        parts = line.strip().split()\n",
    "        \n",
    "        # Format genelde: [Label] [File1] [File2]\n",
    "        label = int(parts[0])\n",
    "        file1 = parts[1]\n",
    "        file2 = parts[2]\n",
    "        \n",
    "        emb1 = get_embedding(model, file1)\n",
    "        emb2 = get_embedding(model, file2)\n",
    "        \n",
    "        if emb1 is not None and emb2 is not None:\n",
    "            score = torch.nn.CosineSimilarity(dim=-1)(emb1, emb2).item()\n",
    "            scores.append(score)\n",
    "            labels.append(label)\n",
    "            \n",
    "    # EER Hesaplama\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VOXCELEB1 TEST SONUÃ‡LARI\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Model: Custom Mini-ECAPA (24kHz, Clean-Trained)\")\n",
    "    print(f\"âœ… EER: %{eer*100:.2f}\")\n",
    "    print(f\"Optimal Threshold: {thresh:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Yorumlama KÄ±lavuzu\n",
    "    print(\"YORUM:\")\n",
    "    if eer*100 < 5.0:\n",
    "        print(\"MÃœKEMMEL! Temiz veriyle eÄŸitilmene raÄŸmen gÃ¼rÃ¼ltÃ¼lÃ¼ veride harika Ã§alÄ±ÅŸÄ±yor.\")\n",
    "    elif eer*100 < 10.0:\n",
    "        print(\"BAÅžARILI. Domain Shift (Dil ve KayÄ±t farkÄ±) makul seviyede.\")\n",
    "    else:\n",
    "        print(\"NORMAL. Modelin sadece temiz TÃ¼rkÃ§e sese Ã¶zelleÅŸmiÅŸ (Domain Gap).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(VOXCELEB_ROOT) and os.path.exists(TEST_LIST_PATH):\n",
    "        run_voxceleb_benchmark()\n",
    "    else:\n",
    "        print(\"HATA: KlasÃ¶r yollarÄ±nÄ± kontrol et!\")\n",
    "        print(f\"Wav KlasÃ¶rÃ¼: {VOXCELEB_ROOT}\")\n",
    "        print(f\"Test Listesi: {TEST_LIST_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac56184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-ECAPA (C=256) YÃ¼kleniyor...\n"
     ]
    }
   ],
   "source": [
    "from ecapa_tdnn_original import ECAPA_TDNN\n",
    "\n",
    "orig_model = load_custom_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1522800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-ECAPA (C=256) YÃ¼kleniyor...\n",
      "Toplam Test Ã‡ifti: 10000\n",
      "ðŸš€ Orijinal Model Testi BaÅŸlÄ±yor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]C:\\Users\\omera\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [10:53<00:00, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ORÄ°JÄ°NAL MODEL (VOXCELEB) SONUÃ‡LARI\n",
      "==================================================\n",
      "Veri Seti: Senin Ã–zel TÃ¼rkÃ§e Datasetin\n",
      "âœ… EER: %3.92\n",
      "Optimal Threshold: 0.3170\n",
      "--------------------------------------------------\n",
      "KARÅžILAÅžTIRMA:\n",
      "Senin Modelin (Mini): %0.56\n",
      "Orijinal Model (Dev) : %3.92\n",
      "\n",
      "ðŸ† KAZANAN: SENÄ°N MODELÄ°N!\n",
      "Yorum: Kendi sahanda (Domain Adaptation) devasa modeli yendin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- AYARLAR ---\n",
    "# Daha Ã¶nce oluÅŸturduÄŸun sabit test Ã§iftleri dosyasÄ±\n",
    "PAIRS_FILE = \"test_pairs_static.csv\" \n",
    "# Orijinal Model KaynaÄŸÄ± (Otomatik iner)\n",
    "SOURCE = \"speechbrain/spkrec-ecapa-voxceleb\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_custom_model():\n",
    "    print(f\"Mini-ECAPA (C=256) YÃ¼kleniyor...\")\n",
    "    model = ECAPA_TDNN(C=1024).to(device)\n",
    "    checkpoint = torch.load(r\"artifacts\\pretrain.model\", map_location=device)\n",
    "    \n",
    "    # Prefix temizliÄŸi\n",
    "    new_state = {}\n",
    "    for k, v in checkpoint.items():\n",
    "        if k.startswith(\"speaker_encoder.\"):\n",
    "            new_state[k.replace(\"speaker_encoder.\", \"\")] = v\n",
    "    \n",
    "    model.load_state_dict(new_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_embedding_original(model, wav_path):\n",
    "    # Dosya kontrolÃ¼\n",
    "    if not os.path.exists(wav_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Sesi yÃ¼kle\n",
    "        wav, sr = torchaudio.load(wav_path)\n",
    "        \n",
    "        # --- Ã–NEMLÄ°: Orijinal model 16kHz ister ---\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "            wav = resampler(wav)\n",
    "            \n",
    "        # Mono yap\n",
    "        if wav.shape[0] > 1: \n",
    "            wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "            \n",
    "        wav = wav.to(device)\n",
    "        \n",
    "        # Inference (SpeechBrain encode_batch bekler)\n",
    "        with torch.no_grad():\n",
    "            emb = model(wav,aug=False)\n",
    "            \n",
    "        # [1, 1, 192] -> [192] dÃ¼zleÅŸtir\n",
    "        return emb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_benchmark():\n",
    "    # 1. Modeli YÃ¼kle\n",
    "    model = load_custom_model()\n",
    "    \n",
    "    # 2. Test Ã‡iftlerini Oku\n",
    "    if not os.path.exists(PAIRS_FILE):\n",
    "        print(f\"HATA: {PAIRS_FILE} bulunamadÄ±! Ã–nce generate_pairs kodunu Ã§alÄ±ÅŸtÄ±r.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(PAIRS_FILE)\n",
    "    print(f\"Toplam Test Ã‡ifti: {len(df)}\")\n",
    "    \n",
    "    scores = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"ðŸš€ Orijinal Model Testi BaÅŸlÄ±yor...\")\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        f1, f2, label = row['file1'], row['file2'], row['label']\n",
    "        \n",
    "        e1 = get_embedding_original(model, f1)\n",
    "        e2 = get_embedding_original(model, f2)\n",
    "        \n",
    "        if e1 is not None and e2 is not None:\n",
    "            # Cosine Similarity\n",
    "            score = torch.nn.CosineSimilarity(dim=-1)(e1, e2).item()\n",
    "            scores.append(score)\n",
    "            labels.append(label)\n",
    "            \n",
    "    # EER Hesaplama\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ORÄ°JÄ°NAL MODEL (VOXCELEB) SONUÃ‡LARI\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Veri Seti: Senin Ã–zel TÃ¼rkÃ§e Datasetin\")\n",
    "    print(f\"âœ… EER: %{eer*100:.2f}\")\n",
    "    print(f\"Optimal Threshold: {thresh:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # KarÅŸÄ±laÅŸtÄ±rma Yorumu\n",
    "    # Senin modelin %0.56 Ã§Ä±kmÄ±ÅŸtÄ±.\n",
    "    my_eer = 0.56 \n",
    "    print(\"KARÅžILAÅžTIRMA:\")\n",
    "    print(f\"Senin Modelin (Mini): %{my_eer:.2f}\")\n",
    "    print(f\"Orijinal Model (Dev) : %{eer*100:.2f}\")\n",
    "    \n",
    "    if my_eer < (eer*100):\n",
    "        print(\"\\nðŸ† KAZANAN: SENÄ°N MODELÄ°N!\")\n",
    "        print(\"Yorum: Kendi sahanda (Domain Adaptation) devasa modeli yendin.\")\n",
    "    else:\n",
    "        print(\"\\nðŸ† KAZANAN: ORÄ°JÄ°NAL MODEL\")\n",
    "        print(\"Yorum: Orijinal modelin genelleÅŸtirme yeteneÄŸi Ã§ok yÃ¼ksekmiÅŸ.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf07f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
